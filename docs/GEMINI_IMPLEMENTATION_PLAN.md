# Gemini AI Implementation Plan for Atlassian MCP Interface

## ğŸš€ **Phase 1: MVP with Gemini AI (This Week)**

### Key Advantage: Gemini's Built-in MCP Support

Gemini AI has **experimental MCP integration** which means we can potentially connect our Atlassian MCP client directly to Gemini for automatic tool calling!

## ğŸ“¦ **Dependencies & Setup**

### Install Gemini SDK:

```bash
npm install @google/genai
npm install commander chalk inquirer ora
npm install zod  # for validation
```

### Environment Setup:

```env
GEMINI_API_KEY=your-gemini-api-key-from-aistudio
ATLASSIAN_CLOUD_ID=65fa3ca6-c0c5-4d04-93d2-88127a2297ff
```

## ğŸ› ï¸ **Implementation Strategy**

### Option 1: Direct MCP Integration (Experimental)

Use Gemini's built-in MCP support to connect directly to our Atlassian MCP client.

### Option 2: Traditional Function Calling (Reliable)

Use Gemini's function calling to map intents to our MCP tools.

**We'll start with Option 2 for reliability, then explore Option 1.**

## ğŸ“‹ **Day-by-Day Implementation**

### Day 1: Gemini Integration & Query Parser

1. Set up Gemini AI client
2. Create intent classification system
3. Test basic natural language understanding

### Day 2: Tool Router & Parameter Mapping

1. Map intents to MCP tools using function declarations
2. Create parameter transformation logic
3. Implement validation

### Day 3: Response Formatter

1. Use Gemini to format MCP responses
2. Create human-readable output templates
3. Add error handling

### Day 4: Interactive CLI

1. Build terminal interface with conversation loop
2. Integrate all components
3. Add help system and commands

### Day 5: Testing & Refinement

1. Test various query types
2. Improve prompts and error handling
3. Add conversation context

## ğŸ¯ **Core Components Implementation**

### 1. Gemini Client (`src/ai/gemini-client.ts`)

```typescript
import { GoogleGenAI } from "@google/genai";

export class GeminiClient {
  private ai: GoogleGenAI;

  constructor(apiKey: string) {
    this.ai = new GoogleGenAI({ apiKey });
  }

  async parseQuery(userQuery: string): Promise<QueryIntent> {
    // Use Gemini to parse natural language to structured intent
  }

  async formatResponse(data: any, queryType: string): Promise<string> {
    // Use Gemini to create human-readable responses
  }
}
```

### 2. Intent Schemas

```typescript
interface QueryIntent {
  action: "search" | "get" | "list" | "create" | "update";
  entity: "tickets" | "projects" | "users" | "pages";
  filters: QueryFilter[];
  parameters: Record<string, any>;
  confidence: number;
}
```

### 3. Function Declarations for Gemini

```typescript
const mcpToolDeclarations = [
  {
    name: "searchJiraIssues",
    description: "Search for Jira tickets using JQL query",
    parametersJsonSchema: {
      type: "object",
      properties: {
        jql: { type: "string", description: "JQL query string" },
        cloudId: { type: "string", description: "Atlassian cloud ID" },
      },
      required: ["jql", "cloudId"],
    },
  },
  // ... more tool declarations
];
```

## ğŸ­ **Supported Query Examples**

### Simple Queries:

- "Show me all open tickets" â†’ `searchJiraIssuesUsingJql(jql: "status != Done")`
- "Get ticket MD-1" â†’ `getJiraIssue(issueIdOrKey: "MD-1")`
- "List all projects" â†’ `getJiraProjects()`

### Complex Queries:

- "Find high priority bugs assigned to John" â†’ `searchJiraIssuesUsingJql(jql: "priority = High AND type = Bug AND assignee = john")`
- "Show tickets created this week" â†’ `searchJiraIssuesUsingJql(jql: "created >= -1w")`

## ğŸ’¬ **Conversation Flow Design**

```
ğŸ¤– Atlassian AI: Hello! I can help you with Jira and Confluence. What would you like to do?

ğŸ‘¤ User: show me all open tickets

ğŸ¤– AI: [Processing...] Let me search for all open tickets...
     [Calling: searchJiraIssuesUsingJql(jql: "status != Done", cloudId: "...")]

     Found 1 open ticket:
     ğŸ“‹ MD-1: "Do the Research on Jira mcp server"
        ğŸ“Š Status: To Do
        ğŸš€ Priority: Highest
        ğŸ‘¤ Assignee: Unassigned
        ğŸ“… Created: 2 days ago

ğŸ‘¤ User: what are the details of MD-1?

ğŸ¤– AI: [Processing...] Getting detailed information for MD-1...
     [Calling: getJiraIssue(issueIdOrKey: "MD-1", cloudId: "...")]

     ğŸ“‹ **Ticket MD-1 Details:**
     **Summary:** Do the Research on Jira mcp server
     **Status:** To Do
     **Priority:** Highest
     **Type:** Submit a request or incident
     **Assignee:** Unassigned
     **Reporter:** Dashrath Yadav
     **Created:** January 28, 2025
     **Updated:** January 30, 2025
     **Description:** [Full description here...]

ğŸ‘¤ User: exit

ğŸ¤– AI: Goodbye! Have a productive day! ğŸ‘‹
```

## ğŸ”§ **Gemini Configuration**

### Model Selection:

- **Primary**: `gemini-2.0-flash-001` (latest, fastest)
- **Fallback**: `gemini-1.5-pro` (more reliable)

### Generation Config:

```typescript
const generationConfig = {
  temperature: 0.1, // Low for consistent parsing
  maxOutputTokens: 1000, // Sufficient for responses
  topP: 0.8,
  topK: 10,
};
```

## ğŸ§ª **Testing Strategy**

### Unit Tests:

1. Query parsing accuracy (95%+ correct intent detection)
2. Parameter extraction validation
3. Response formatting quality

### Integration Tests:

1. End-to-end query processing
2. MCP tool calling with real data
3. Error handling scenarios

### User Acceptance Tests:

1. Natural conversation flow
2. Response time (< 3 seconds)
3. Human-readable output quality

## ğŸš€ **Implementation Steps**

### Step 1: Basic Setup

```bash
# Create package.json updates
npm install @google/genai commander chalk inquirer ora zod

# Set up environment
echo "GEMINI_API_KEY=your-api-key" >> .env
```

### Step 2: Create Core Structure

```
src/ai/
â”œâ”€â”€ gemini-client.ts      # Main Gemini integration
â”œâ”€â”€ query-parser.ts       # Parse user queries
â”œâ”€â”€ response-formatter.ts # Format responses
â””â”€â”€ prompt-templates.ts   # Gemini prompts

src/cli/
â”œâ”€â”€ ai-cli.ts            # Interactive terminal
â””â”€â”€ command-processor.ts # Process commands
```

### Step 3: Build & Test

```bash
npx tsx src/cli/ai-cli.ts
```

## ğŸ“ˆ **Success Metrics**

1. âœ… **Accuracy**: 90%+ correct intent detection
2. âœ… **Speed**: < 3 seconds average response
3. âœ… **Coverage**: Support 10+ query types
4. âœ… **UX**: Smooth conversational experience
5. âœ… **Reliability**: Graceful error handling

This plan leverages Gemini's strengths while building on our existing MCP infrastructure for a powerful AI-driven Atlassian interface.
